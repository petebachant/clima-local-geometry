{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44539ead",
   "metadata": {
    "papermill": {
     "duration": 0.00789,
     "end_time": "2026-02-27T17:44:03.928714",
     "exception": false,
     "start_time": "2026-02-27T17:44:03.920824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Compare kernel statistics\n",
    "\n",
    "This notebook compares kernel statistics between two Nsight Systems SQLite report files.\n",
    "\n",
    "We'll specifically compare the `set_prognostic_edmf_precomputed_quantities_precipitation` kernel between:\n",
    "- `baseline.sqlite` - baseline run\n",
    "- `mod.sqlite` - modified run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd6072",
   "metadata": {
    "papermill": {
     "duration": 0.002406,
     "end_time": "2026-02-27T17:44:03.934195",
     "exception": false,
     "start_time": "2026-02-27T17:44:03.931789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c83a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T17:44:03.940160Z",
     "iopub.status.busy": "2026-02-27T17:44:03.939979Z",
     "iopub.status.idle": "2026-02-27T17:44:04.170793Z",
     "shell.execute_reply": "2026-02-27T17:44:04.169523Z"
    },
    "papermill": {
     "duration": 0.23553,
     "end_time": "2026-02-27T17:44:04.172125",
     "exception": false,
     "start_time": "2026-02-27T17:44:03.936595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "import re\n",
    "import sqlite3\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d524cf",
   "metadata": {
    "papermill": {
     "duration": 0.002555,
     "end_time": "2026-02-27T17:44:04.178762",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.176207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689e1f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T17:44:04.185506Z",
     "iopub.status.busy": "2026-02-27T17:44:04.185266Z",
     "iopub.status.idle": "2026-02-27T17:44:04.192612Z",
     "shell.execute_reply": "2026-02-27T17:44:04.191718Z"
    },
    "papermill": {
     "duration": 0.011442,
     "end_time": "2026-02-27T17:44:04.193153",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.181711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_kernel_stats(db_path, kernel_name_pattern):\n",
    "    \"\"\"\n",
    "    Extract kernel statistics from an nsys SQLite database.\n",
    "\n",
    "    Args:\n",
    "        db_path: Path to the SQLite database file\n",
    "        kernel_name_pattern: SQL LIKE pattern to match kernel names\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with aggregated statistics and list of all kernel invocations\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Query to get all kernel invocations with the specified name\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        s.value as kernelName,\n",
    "        k.start,\n",
    "        k.end,\n",
    "        (k.end - k.start) as duration_ns,\n",
    "        k.gridX,\n",
    "        k.gridY,\n",
    "        k.gridZ,\n",
    "        k.blockX,\n",
    "        k.blockY,\n",
    "        k.blockZ,\n",
    "        k.registersPerThread,\n",
    "        k.staticSharedMemory,\n",
    "        k.dynamicSharedMemory,\n",
    "        k.localMemoryPerThread,\n",
    "        k.localMemoryTotal,\n",
    "        k.deviceId,\n",
    "        k.streamId,\n",
    "        k.launchType,\n",
    "        k.sharedMemoryExecuted,\n",
    "        k.correlationId,\n",
    "        k.globalPid\n",
    "    FROM CUPTI_ACTIVITY_KIND_KERNEL k\n",
    "    JOIN StringIds s ON k.demangledName = s.id\n",
    "    WHERE s.value LIKE ?\n",
    "    ORDER BY k.start\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(query, (kernel_name_pattern,))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    if not rows:\n",
    "        conn.close()\n",
    "        return None, None\n",
    "\n",
    "    # Calculate statistics\n",
    "    durations = [row[3] for row in rows]\n",
    "\n",
    "    stats = {\n",
    "        \"kernel_name\": rows[0][0],\n",
    "        \"invocation_count\": len(rows),\n",
    "        \"duration_ns\": {\n",
    "            \"total\": sum(durations),\n",
    "            \"mean\": sum(durations) / len(durations),\n",
    "            \"min\": min(durations),\n",
    "            \"max\": max(durations),\n",
    "            \"median\": sorted(durations)[len(durations) // 2],\n",
    "        },\n",
    "        \"grid_dims\": {\n",
    "            \"x\": rows[0][4],\n",
    "            \"y\": rows[0][5],\n",
    "            \"z\": rows[0][6],\n",
    "        },\n",
    "        \"block_dims\": {\n",
    "            \"x\": rows[0][7],\n",
    "            \"y\": rows[0][8],\n",
    "            \"z\": rows[0][9],\n",
    "        },\n",
    "        \"registers_per_thread\": rows[0][10],\n",
    "        \"static_shared_memory\": rows[0][11],\n",
    "        \"dynamic_shared_memory\": rows[0][12],\n",
    "        \"local_memory_per_thread\": rows[0][13],\n",
    "        \"local_memory_total\": rows[0][14],\n",
    "        \"device_id\": rows[0][15],\n",
    "        \"stream_id\": rows[0][16],\n",
    "        \"launch_type\": rows[0][17],\n",
    "        \"shared_memory_executed\": rows[0][18],\n",
    "        \"correlation_id\": rows[0][19],\n",
    "        \"global_pid\": rows[0][20],\n",
    "    }\n",
    "\n",
    "    # Calculate theoretical occupancy\n",
    "    # Occupancy = (active warps per SM) / (max warps per SM) * 100%\n",
    "    block_size = rows[0][7] * rows[0][8] * rows[0][9]\n",
    "    warps_per_block = (block_size + 31) // 32\n",
    "    max_warps_per_sm = 48\n",
    "\n",
    "    # Register file size: ~49KB per SM (determined by occupancy calculator matching nsys)\n",
    "    max_registers_per_sm = 49152  # registers available per SM\n",
    "    registers_per_block = rows[0][10] * block_size\n",
    "    blocks_limited_by_registers = (\n",
    "        max(1, max_registers_per_sm // registers_per_block)\n",
    "        if registers_per_block > 0\n",
    "        else 8\n",
    "    )\n",
    "\n",
    "    # Shared memory limit (if applicable, but usually not limiting for this kernel)\n",
    "    max_shared_mem_per_sm = 96000\n",
    "    shared_mem_per_block = rows[0][11] + rows[0][12]\n",
    "    blocks_limited_by_shared_mem = (\n",
    "        max(1, max_shared_mem_per_sm // shared_mem_per_block)\n",
    "        if shared_mem_per_block > 0\n",
    "        else 8\n",
    "    )\n",
    "\n",
    "    # Effective blocks per SM is the minimum of register and shared memory constraints\n",
    "    blocks_per_sm = min(\n",
    "        blocks_limited_by_registers, blocks_limited_by_shared_mem\n",
    "    )\n",
    "\n",
    "    # Calculate occupancy\n",
    "    active_warps = warps_per_block * blocks_per_sm\n",
    "    occupancy = (active_warps / max_warps_per_sm) * 100\n",
    "    stats[\"theoretical_occupancy\"] = occupancy\n",
    "    conn.close()\n",
    "    return stats, rows\n",
    "\n",
    "\n",
    "def get_launch_type_name(launch_type_id):\n",
    "    \"\"\"Convert launch type ID to human-readable name.\"\"\"\n",
    "    launch_types = {\n",
    "        0: \"Regular\",\n",
    "        1: \"Cooperative\",\n",
    "    }\n",
    "    return launch_types.get(launch_type_id, f\"Unknown ({launch_type_id})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810fa4e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T17:44:04.199440Z",
     "iopub.status.busy": "2026-02-27T17:44:04.199296Z",
     "iopub.status.idle": "2026-02-27T17:44:04.202590Z",
     "shell.execute_reply": "2026-02-27T17:44:04.201683Z"
    },
    "papermill": {
     "duration": 0.007259,
     "end_time": "2026-02-27T17:44:04.203099",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.195840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_duration(ns):\n",
    "    \"\"\"Convert nanoseconds to human-readable format.\"\"\"\n",
    "    if ns < 1000:\n",
    "        return f\"{ns:.2f} ns\"\n",
    "    elif ns < 1_000_000:\n",
    "        return f\"{ns / 1000:.2f} µs\"\n",
    "    elif ns < 1_000_000_000:\n",
    "        return f\"{ns / 1_000_000:.2f} ms\"\n",
    "    else:\n",
    "        return f\"{ns / 1_000_000_000:.2f} s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff337d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T17:44:04.209553Z",
     "iopub.status.busy": "2026-02-27T17:44:04.209410Z",
     "iopub.status.idle": "2026-02-27T17:44:04.237189Z",
     "shell.execute_reply": "2026-02-27T17:44:04.236197Z"
    },
    "papermill": {
     "duration": 0.031875,
     "end_time": "2026-02-27T17:44:04.237888",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.206013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_stats(baseline_stats, mod_stats):\n",
    "    \"\"\"\n",
    "    Compare two sets of kernel statistics and display results in a single table.\n",
    "\n",
    "    Args:\n",
    "        baseline_stats: Statistics from baseline run\n",
    "        mod_stats: Statistics from modified run\n",
    "    \"\"\"\n",
    "    if baseline_stats is None or mod_stats is None:\n",
    "        print(\n",
    "            \"Error: Could not retrieve statistics from one or both databases\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 140)\n",
    "    print(f\"KERNEL: {baseline_stats['kernel_name']}\")\n",
    "    print(\"=\" * 140 + \"\\n\")\n",
    "\n",
    "    # Build comprehensive data structure with all metrics\n",
    "    data = {\"Metric\": [], \"Baseline\": [], \"Modified\": [], \"% Change\": []}\n",
    "\n",
    "    # Timing Statistics\n",
    "    metrics = [\n",
    "        (\n",
    "            \"Invocations\",\n",
    "            baseline_stats[\"invocation_count\"],\n",
    "            mod_stats[\"invocation_count\"],\n",
    "            True,\n",
    "        ),\n",
    "        (\n",
    "            \"Total Duration\",\n",
    "            baseline_stats[\"duration_ns\"][\"total\"],\n",
    "            mod_stats[\"duration_ns\"][\"total\"],\n",
    "            False,\n",
    "        ),\n",
    "        (\n",
    "            \"Mean Duration\",\n",
    "            baseline_stats[\"duration_ns\"][\"mean\"],\n",
    "            mod_stats[\"duration_ns\"][\"mean\"],\n",
    "            False,\n",
    "        ),\n",
    "        (\n",
    "            \"Median Duration\",\n",
    "            baseline_stats[\"duration_ns\"][\"median\"],\n",
    "            mod_stats[\"duration_ns\"][\"median\"],\n",
    "            False,\n",
    "        ),\n",
    "        (\n",
    "            \"Min Duration\",\n",
    "            baseline_stats[\"duration_ns\"][\"min\"],\n",
    "            mod_stats[\"duration_ns\"][\"min\"],\n",
    "            False,\n",
    "        ),\n",
    "        (\n",
    "            \"Max Duration\",\n",
    "            baseline_stats[\"duration_ns\"][\"max\"],\n",
    "            mod_stats[\"duration_ns\"][\"max\"],\n",
    "            False,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    for metric_name, baseline_val, mod_val, is_count in metrics:\n",
    "        data[\"Metric\"].append(metric_name)\n",
    "\n",
    "        if is_count:\n",
    "            data[\"Baseline\"].append(f\"{baseline_val:,}\")\n",
    "            data[\"Modified\"].append(f\"{mod_val:,}\")\n",
    "            pct = (\n",
    "                (mod_val - baseline_val) / baseline_val * 100\n",
    "                if baseline_val > 0\n",
    "                else 0\n",
    "            )\n",
    "        else:\n",
    "            data[\"Baseline\"].append(format_duration(baseline_val))\n",
    "            data[\"Modified\"].append(format_duration(mod_val))\n",
    "            pct = (mod_val - baseline_val) / baseline_val * 100\n",
    "\n",
    "        sign = \"+\" if pct > 0 else \"\"\n",
    "        data[\"% Change\"].append(f\"{sign}{pct:.2f}%\")\n",
    "\n",
    "    # Kernel Dimensions & Launch\n",
    "    data[\"Metric\"].append(\"Grid Dimensions\")\n",
    "    data[\"Baseline\"].append(\n",
    "        f\"<{baseline_stats['grid_dims']['x']}, {baseline_stats['grid_dims']['y']}, {baseline_stats['grid_dims']['z']}>\"\n",
    "    )\n",
    "    data[\"Modified\"].append(\n",
    "        f\"<{mod_stats['grid_dims']['x']}, {mod_stats['grid_dims']['y']}, {mod_stats['grid_dims']['z']}>\"\n",
    "    )\n",
    "    data[\"% Change\"].append(\"—\")\n",
    "\n",
    "    data[\"Metric\"].append(\"Block Dimensions\")\n",
    "    data[\"Baseline\"].append(\n",
    "        f\"<{baseline_stats['block_dims']['x']}, {baseline_stats['block_dims']['y']}, {baseline_stats['block_dims']['z']}>\"\n",
    "    )\n",
    "    data[\"Modified\"].append(\n",
    "        f\"<{mod_stats['block_dims']['x']}, {mod_stats['block_dims']['y']}, {mod_stats['block_dims']['z']}>\"\n",
    "    )\n",
    "    data[\"% Change\"].append(\"—\")\n",
    "\n",
    "    block_size_baseline = (\n",
    "        baseline_stats[\"block_dims\"][\"x\"]\n",
    "        * baseline_stats[\"block_dims\"][\"y\"]\n",
    "        * baseline_stats[\"block_dims\"][\"z\"]\n",
    "    )\n",
    "    block_size_mod = (\n",
    "        mod_stats[\"block_dims\"][\"x\"]\n",
    "        * mod_stats[\"block_dims\"][\"y\"]\n",
    "        * mod_stats[\"block_dims\"][\"z\"]\n",
    "    )\n",
    "    data[\"Metric\"].append(\"Block Size (threads)\")\n",
    "    data[\"Baseline\"].append(f\"{block_size_baseline:,}\")\n",
    "    data[\"Modified\"].append(f\"{block_size_mod:,}\")\n",
    "    data[\"% Change\"].append(\"—\")\n",
    "\n",
    "    grid_size_baseline = (\n",
    "        baseline_stats[\"grid_dims\"][\"x\"]\n",
    "        * baseline_stats[\"grid_dims\"][\"y\"]\n",
    "        * baseline_stats[\"grid_dims\"][\"z\"]\n",
    "    )\n",
    "    grid_size_mod = (\n",
    "        mod_stats[\"grid_dims\"][\"x\"]\n",
    "        * mod_stats[\"grid_dims\"][\"y\"]\n",
    "        * mod_stats[\"grid_dims\"][\"z\"]\n",
    "    )\n",
    "    data[\"Metric\"].append(\"Grid Size (blocks)\")\n",
    "    data[\"Baseline\"].append(f\"{grid_size_baseline:,}\")\n",
    "    data[\"Modified\"].append(f\"{grid_size_mod:,}\")\n",
    "    data[\"% Change\"].append(\"—\")\n",
    "\n",
    "    total_threads_baseline = grid_size_baseline * block_size_baseline\n",
    "    total_threads_mod = grid_size_mod * block_size_mod\n",
    "    data[\"Metric\"].append(\"Total Threads\")\n",
    "    data[\"Baseline\"].append(f\"{total_threads_baseline:,}\")\n",
    "    data[\"Modified\"].append(f\"{total_threads_mod:,}\")\n",
    "    data[\"% Change\"].append(\"—\")\n",
    "\n",
    "    data[\"Metric\"].append(\"Launch Type\")\n",
    "    data[\"Baseline\"].append(\n",
    "        get_launch_type_name(baseline_stats[\"launch_type\"])\n",
    "    )\n",
    "    data[\"Modified\"].append(get_launch_type_name(mod_stats[\"launch_type\"]))\n",
    "    data[\"% Change\"].append(\"—\")\n",
    "\n",
    "    # Register Usage\n",
    "    data[\"Metric\"].append(\"Registers Per Thread\")\n",
    "    data[\"Baseline\"].append(f\"{baseline_stats['registers_per_thread']}\")\n",
    "    data[\"Modified\"].append(f\"{mod_stats['registers_per_thread']}\")\n",
    "    if (\n",
    "        baseline_stats[\"registers_per_thread\"]\n",
    "        != mod_stats[\"registers_per_thread\"]\n",
    "    ):\n",
    "        pct = (\n",
    "            (\n",
    "                mod_stats[\"registers_per_thread\"]\n",
    "                - baseline_stats[\"registers_per_thread\"]\n",
    "            )\n",
    "            / baseline_stats[\"registers_per_thread\"]\n",
    "            * 100\n",
    "        )\n",
    "        sign = \"+\" if pct > 0 else \"\"\n",
    "        data[\"% Change\"].append(f\"{sign}{pct:.2f}%\")\n",
    "    else:\n",
    "        data[\"% Change\"].append(\"—\")\n",
    "\n",
    "    # Memory Usage\n",
    "    memory_metrics = [\n",
    "        (\n",
    "            \"Static Shared Memory (bytes)\",\n",
    "            baseline_stats[\"static_shared_memory\"],\n",
    "            mod_stats[\"static_shared_memory\"],\n",
    "        ),\n",
    "        (\n",
    "            \"Dynamic Shared Memory (bytes)\",\n",
    "            baseline_stats[\"dynamic_shared_memory\"],\n",
    "            mod_stats[\"dynamic_shared_memory\"],\n",
    "        ),\n",
    "        (\n",
    "            \"Shared Memory Executed (bytes)\",\n",
    "            baseline_stats[\"shared_memory_executed\"],\n",
    "            mod_stats[\"shared_memory_executed\"],\n",
    "        ),\n",
    "        (\n",
    "            \"Local Memory Per Thread (bytes)\",\n",
    "            baseline_stats[\"local_memory_per_thread\"],\n",
    "            mod_stats[\"local_memory_per_thread\"],\n",
    "        ),\n",
    "        (\n",
    "            \"Local Memory Total (bytes)\",\n",
    "            baseline_stats[\"local_memory_total\"],\n",
    "            mod_stats[\"local_memory_total\"],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    for metric_name, baseline_val, mod_val in memory_metrics:\n",
    "        data[\"Metric\"].append(metric_name)\n",
    "        data[\"Baseline\"].append(f\"{baseline_val:,}\")\n",
    "        data[\"Modified\"].append(f\"{mod_val:,}\")\n",
    "\n",
    "        if baseline_val == mod_val:\n",
    "            data[\"% Change\"].append(\"—\")\n",
    "        elif baseline_val == 0:\n",
    "            data[\"% Change\"].append(\"—\")\n",
    "        else:\n",
    "            pct = (mod_val - baseline_val) / baseline_val * 100\n",
    "            sign = \"+\" if pct > 0 else \"\"\n",
    "            data[\"% Change\"].append(f\"{sign}{pct:.2f}%\")\n",
    "\n",
    "    # Theoretical Occupancy\n",
    "    data[\"Metric\"].append(\"Theoretical Occupancy (%)\")\n",
    "    data[\"Baseline\"].append(f\"{baseline_stats['theoretical_occupancy']:.1f}%\")\n",
    "    data[\"Modified\"].append(f\"{mod_stats['theoretical_occupancy']:.1f}%\")\n",
    "    data[\"% Change\"].append(\"—\")\n",
    "\n",
    "    # Create and display the combined dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    display(df)\n",
    "\n",
    "    # Performance summary\n",
    "    print(\"\\n\" + \"=\" * 140)\n",
    "    baseline_mean = baseline_stats[\"duration_ns\"][\"mean\"]\n",
    "    mod_mean = mod_stats[\"duration_ns\"][\"mean\"]\n",
    "\n",
    "    if mod_mean < baseline_mean:\n",
    "        improvement = ((baseline_mean - mod_mean) / baseline_mean) * 100\n",
    "        print(\n",
    "            f\"✅ Modified version is {improvement:.2f}% FASTER (mean duration)\"\n",
    "        )\n",
    "    elif mod_mean > baseline_mean:\n",
    "        regression = ((mod_mean - baseline_mean) / baseline_mean) * 100\n",
    "        print(\n",
    "            f\"⚠️  Modified version is {regression:.2f}% SLOWER (mean duration)\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"➡️  No change in mean duration\")\n",
    "\n",
    "    print(\"=\" * 140)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc87c12",
   "metadata": {
    "papermill": {
     "duration": 0.00247,
     "end_time": "2026-02-27T17:44:04.243037",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.240567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b539950d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T17:44:04.249243Z",
     "iopub.status.busy": "2026-02-27T17:44:04.249082Z",
     "iopub.status.idle": "2026-02-27T17:44:04.253323Z",
     "shell.execute_reply": "2026-02-27T17:44:04.252382Z"
    },
    "papermill": {
     "duration": 0.008407,
     "end_time": "2026-02-27T17:44:04.253874",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.245467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found baseline database: ../results/nsys/baseline.sqlite\n",
      "✓ Found modified database: ../results/nsys/mod.sqlite\n"
     ]
    }
   ],
   "source": [
    "# Database paths\n",
    "baseline_db = Path(\"../results/nsys/baseline.sqlite\")\n",
    "mod_db = Path(\"../results/nsys/mod.sqlite\")\n",
    "\n",
    "# Kernel name pattern to match (avoid fragile line numbers)\n",
    "kernel_pattern = \"%set_prognostic_edmf_precomputed_quantities_precipitation%\"\n",
    "\n",
    "# Check if files exist\n",
    "if not baseline_db.exists():\n",
    "    print(f\"Error: Baseline database not found: {baseline_db}\")\n",
    "else:\n",
    "    print(f\"✓ Found baseline database: {baseline_db}\")\n",
    "\n",
    "if not mod_db.exists():\n",
    "    print(f\"Error: Modified database not found: {mod_db}\")\n",
    "else:\n",
    "    print(f\"✓ Found modified database: {mod_db}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433071f",
   "metadata": {
    "papermill": {
     "duration": 0.002651,
     "end_time": "2026-02-27T17:44:04.259298",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.256647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compare kernel statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8fe8c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T17:44:04.265670Z",
     "iopub.status.busy": "2026-02-27T17:44:04.265524Z",
     "iopub.status.idle": "2026-02-27T17:44:04.337422Z",
     "shell.execute_reply": "2026-02-27T17:44:04.336628Z"
    },
    "papermill": {
     "duration": 0.07612,
     "end_time": "2026-02-27T17:44:04.338027",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.261907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting the hottest kernel from baseline...\n",
      "\n",
      "Top 5 kernels in baseline (by total time):\n",
      "   469.02 ms  [  25 invocations] set_microphysics_tendency_cache__FILE_ClimaAtmos_jl_src_cache_microphysics_cache_jl_L1096\n",
      "   390.14 ms  [7515 invocations] foreach_FILE_ClimaCore_tlvj6_src_MatrixFields_field_name_set_jl_L81\n",
      "   283.51 ms  [ 450 invocations] run_field_matrix_solver__FILE_ClimaCore_tlvj6_src_MatrixFields_field_matrix_solver_jl_L352\n",
      "   249.36 ms  [ 990 invocations] run_field_matrix_solver__FILE_ClimaCore_tlvj6_src_MatrixFields_field_matrix_solver_jl_L354\n",
      "    87.80 ms  [4185 invocations] regridded_snapshot__FILE_ClimaUtilities_5ClV5_ext_DataHandlingExt_jl_L666\n",
      "\n",
      "Top 5 kernels in modified (by total time):\n",
      "   388.85 ms  [7515 invocations] foreach_FILE_ClimaCore_tlvj6_src_MatrixFields_field_name_set_jl_L81\n",
      "   282.36 ms  [ 450 invocations] run_field_matrix_solver__FILE_ClimaCore_tlvj6_src_MatrixFields_field_matrix_solver_jl_L352\n",
      "   254.46 ms  [  25 invocations] set_microphysics_tendency_cache__FILE_ClimaAtmos_jl_mod_src_cache_microphysics_cache_jl_L1096\n",
      "   249.84 ms  [ 990 invocations] run_field_matrix_solver__FILE_ClimaCore_tlvj6_src_MatrixFields_field_matrix_solver_jl_L354\n",
      "    87.39 ms  [4185 invocations] regridded_snapshot__FILE_ClimaUtilities_5ClV5_ext_DataHandlingExt_jl_L666\n",
      "Selected baseline kernel: set_microphysics_tendency_cache__FILE_ClimaAtmos_jl_src_cache_microphysics_cache_jl_L1096 (total=469.02 ms)\n",
      "Selected modified kernel: set_microphysics_tendency_cache__FILE_ClimaAtmos_jl_mod_src_cache_microphysics_cache_jl_L1096 (total=254.46 ms, score=0.978)\n"
     ]
    }
   ],
   "source": [
    "def normalize_kernel_name(name):\n",
    "    \"\"\"Normalize kernel names for robust matching.\"\"\"\n",
    "    normalized = unicodedata.normalize(\"NFKC\", name)\n",
    "    normalized = \"\".join(ch for ch in normalized if ch.isprintable())\n",
    "    normalized = re.sub(r\"\\s+\", \" \", normalized).strip()\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def strip_mod_suffix(name):\n",
    "    \"\"\"Remove a loose mod suffix for matching.\"\"\"\n",
    "    return re.sub(r\"(?:_|\\s)mod\\b\", \"\", name).strip()\n",
    "\n",
    "\n",
    "def list_top_kernels(db_path, pattern=\"%\", limit=15):\n",
    "    \"\"\"\n",
    "    List top kernels by total duration, filtered by a name pattern.\n",
    "\n",
    "    Args:\n",
    "        db_path: Path to SQLite database\n",
    "        pattern: SQL LIKE pattern for kernel names\n",
    "        limit: Number of kernels to return\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT s.value as kernelName, SUM(k.end - k.start) as total_ns, COUNT(*) as count\n",
    "    FROM CUPTI_ACTIVITY_KIND_KERNEL k\n",
    "    JOIN StringIds s ON k.demangledName = s.id\n",
    "    WHERE s.value LIKE ?\n",
    "    GROUP BY s.value\n",
    "    ORDER BY total_ns DESC\n",
    "    LIMIT ?\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(query, (pattern, limit))\n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def select_kernel_name(baseline_top, mod_top):\n",
    "    \"\"\"\n",
    "    Select the most expensive baseline kernel and the closest name match in modified.\n",
    "    \"\"\"\n",
    "    if not baseline_top:\n",
    "        raise RuntimeError(\"No kernels matched in baseline\")\n",
    "\n",
    "    if not mod_top:\n",
    "        raise RuntimeError(\"No kernels matched in modified\")\n",
    "\n",
    "    baseline_kernel, baseline_total, _ = baseline_top[0]\n",
    "    baseline_norm = strip_mod_suffix(normalize_kernel_name(baseline_kernel))\n",
    "\n",
    "    print(\n",
    "        f\"Selected baseline kernel: {baseline_kernel} (total={format_duration(baseline_total)})\"\n",
    "    )\n",
    "\n",
    "    best = None\n",
    "    for mod_kernel, mod_total, _ in mod_top:\n",
    "        mod_norm = strip_mod_suffix(normalize_kernel_name(mod_kernel))\n",
    "        score = difflib.SequenceMatcher(None, baseline_norm, mod_norm).ratio()\n",
    "        candidate = (score, mod_total, mod_kernel)\n",
    "        if best is None or candidate > best:\n",
    "            best = candidate\n",
    "\n",
    "    best_score, best_total, best_kernel = best\n",
    "    print(\n",
    "        f\"Selected modified kernel: {best_kernel} (total={format_duration(best_total)}, score={best_score:.3f})\"\n",
    "    )\n",
    "\n",
    "    return baseline_kernel, best_kernel\n",
    "\n",
    "\n",
    "# Automatically select the hottest kernel from baseline (no hardcoded patterns)\n",
    "print(\"Selecting the hottest kernel from baseline...\\n\")\n",
    "\n",
    "print(\"Top 5 kernels in baseline (by total time):\")\n",
    "baseline_top = list_top_kernels(baseline_db, pattern=\"%\", limit=5)\n",
    "for kernel_name, total_ns, count in baseline_top:\n",
    "    print(f\"  {format_duration(total_ns):>10}  [{count:4d} invocations] {kernel_name}\")\n",
    "\n",
    "print(\"\\nTop 5 kernels in modified (by total time):\")\n",
    "mod_top = list_top_kernels(mod_db, pattern=\"%\", limit=5)\n",
    "for kernel_name, total_ns, count in mod_top:\n",
    "    print(f\"  {format_duration(total_ns):>10}  [{count:4d} invocations] {kernel_name}\")\n",
    "\n",
    "baseline_kernel_name, mod_kernel_name = select_kernel_name(\n",
    "    baseline_top, mod_top\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36772ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T17:44:04.345238Z",
     "iopub.status.busy": "2026-02-27T17:44:04.345090Z",
     "iopub.status.idle": "2026-02-27T17:44:04.371149Z",
     "shell.execute_reply": "2026-02-27T17:44:04.370351Z"
    },
    "papermill": {
     "duration": 0.030064,
     "end_time": "2026-02-27T17:44:04.371631",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.341567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================================================================================\n",
      "KERNEL: set_microphysics_tendency_cache__FILE_ClimaAtmos_jl_src_cache_microphysics_cache_jl_L1096\n",
      "============================================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Modified</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Invocations</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total Duration</td>\n",
       "      <td>469.02 ms</td>\n",
       "      <td>254.46 ms</td>\n",
       "      <td>-45.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean Duration</td>\n",
       "      <td>18.76 ms</td>\n",
       "      <td>10.18 ms</td>\n",
       "      <td>-45.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Median Duration</td>\n",
       "      <td>18.71 ms</td>\n",
       "      <td>10.18 ms</td>\n",
       "      <td>-45.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Min Duration</td>\n",
       "      <td>18.64 ms</td>\n",
       "      <td>10.14 ms</td>\n",
       "      <td>-45.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Max Duration</td>\n",
       "      <td>20.22 ms</td>\n",
       "      <td>10.23 ms</td>\n",
       "      <td>-49.44%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grid Dimensions</td>\n",
       "      <td>&lt;4, 4, 1536&gt;</td>\n",
       "      <td>&lt;4, 4, 1536&gt;</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Block Dimensions</td>\n",
       "      <td>&lt;64, 1, 1&gt;</td>\n",
       "      <td>&lt;64, 1, 1&gt;</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Block Size (threads)</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grid Size (blocks)</td>\n",
       "      <td>24,576</td>\n",
       "      <td>24,576</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Total Threads</td>\n",
       "      <td>1,572,864</td>\n",
       "      <td>1,572,864</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Launch Type</td>\n",
       "      <td>Cooperative</td>\n",
       "      <td>Cooperative</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Registers Per Thread</td>\n",
       "      <td>255</td>\n",
       "      <td>93</td>\n",
       "      <td>-63.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Static Shared Memory (bytes)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dynamic Shared Memory (bytes)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Shared Memory Executed (bytes)</td>\n",
       "      <td>8,192</td>\n",
       "      <td>32,768</td>\n",
       "      <td>+300.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Local Memory Per Thread (bytes)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Local Memory Total (bytes)</td>\n",
       "      <td>1,928,724,480</td>\n",
       "      <td>1,723,465,728</td>\n",
       "      <td>-10.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Theoretical Occupancy (%)</td>\n",
       "      <td>12.5%</td>\n",
       "      <td>33.3%</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Metric       Baseline       Modified  % Change\n",
       "0                       Invocations             25             25     0.00%\n",
       "1                    Total Duration      469.02 ms      254.46 ms   -45.75%\n",
       "2                     Mean Duration       18.76 ms       10.18 ms   -45.75%\n",
       "3                   Median Duration       18.71 ms       10.18 ms   -45.59%\n",
       "4                      Min Duration       18.64 ms       10.14 ms   -45.62%\n",
       "5                      Max Duration       20.22 ms       10.23 ms   -49.44%\n",
       "6                   Grid Dimensions   <4, 4, 1536>   <4, 4, 1536>         —\n",
       "7                  Block Dimensions     <64, 1, 1>     <64, 1, 1>         —\n",
       "8              Block Size (threads)             64             64         —\n",
       "9                Grid Size (blocks)         24,576         24,576         —\n",
       "10                    Total Threads      1,572,864      1,572,864         —\n",
       "11                      Launch Type    Cooperative    Cooperative         —\n",
       "12             Registers Per Thread            255             93   -63.53%\n",
       "13     Static Shared Memory (bytes)              0              0         —\n",
       "14    Dynamic Shared Memory (bytes)              0              0         —\n",
       "15   Shared Memory Executed (bytes)          8,192         32,768  +300.00%\n",
       "16  Local Memory Per Thread (bytes)              0              0         —\n",
       "17       Local Memory Total (bytes)  1,928,724,480  1,723,465,728   -10.64%\n",
       "18        Theoretical Occupancy (%)          12.5%          33.3%         —"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================================================================================\n",
      "✅ Modified version is 45.75% FASTER (mean duration)\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get statistics from both databases\n",
    "if baseline_kernel_name is None or mod_kernel_name is None:\n",
    "    print(\"Error: Missing kernel name selection; check the listing above.\")\n",
    "else:\n",
    "    baseline_stats, baseline_rows = get_kernel_stats(\n",
    "        baseline_db, baseline_kernel_name\n",
    "    )\n",
    "    mod_stats, mod_rows = get_kernel_stats(mod_db, mod_kernel_name)\n",
    "\n",
    "    # Compare and display results\n",
    "    compare_stats(baseline_stats, mod_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7608080c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T17:44:04.378862Z",
     "iopub.status.busy": "2026-02-27T17:44:04.378718Z",
     "iopub.status.idle": "2026-02-27T17:44:04.387163Z",
     "shell.execute_reply": "2026-02-27T17:44:04.386484Z"
    },
    "papermill": {
     "duration": 0.012608,
     "end_time": "2026-02-27T17:44:04.387651",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.375043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>mod</th>\n",
       "      <th>diff_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.286</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-16.083916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.341</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-6.158358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.412</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-2.912621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline   mod   diff_pct\n",
       "0     0.286  0.24 -16.083916\n",
       "1     0.341  0.32  -6.158358\n",
       "2     0.412  0.40  -2.912621"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare SYPD\n",
    "\n",
    "log_path_template = \"../.calkit/slurm/logs/nsys-{case}.out\"\n",
    "\n",
    "\n",
    "def get_sypd_time_series(case) -> list[float]:\n",
    "    with open(log_path_template.format(case=case)) as f:\n",
    "        lines = f.readlines()\n",
    "    sypd_time_series = []\n",
    "    for line in lines:\n",
    "        if \"estimated_sypd =\" in line and \"Inf\" not in line:\n",
    "            sypd_time_series.append(float(line.split()[-1].replace('\"', \"\")))\n",
    "    return sypd_time_series\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"baseline\": get_sypd_time_series(\"baseline\"),\n",
    "        \"mod\": get_sypd_time_series(\"mod\"),\n",
    "    }\n",
    ")\n",
    "df[\"diff_pct\"] = (df[\"mod\"] - df[\"baseline\"]) / df[\"baseline\"] * 100\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c556128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T17:44:04.394575Z",
     "iopub.status.busy": "2026-02-27T17:44:04.394434Z",
     "iopub.status.idle": "2026-02-27T17:44:04.570359Z",
     "shell.execute_reply": "2026-02-27T17:44:04.569355Z"
    },
    "papermill": {
     "duration": 0.180441,
     "end_time": "2026-02-27T17:44:04.571214",
     "exception": false,
     "start_time": "2026-02-27T17:44:04.390773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Profiling Duration:\n",
      "  Baseline: 3.25 s\n",
      "  Modified: 3.13 s\n",
      "  ✅ Modified run is 3.62% SHORTER overall\n",
      "\n",
      "Total GPU Kernel Time:\n",
      "  Baseline: 3.19 s\n",
      "  Modified: 2.97 s\n",
      "  Change: -7.12%\n",
      "\n",
      "CPU/Sync Overhead (Total Duration - GPU Time):\n",
      "  Baseline: 56.39 ms\n",
      "  Modified: 166.11 ms\n",
      "  ⚠️  Modified has 194.56% MORE overhead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel Count Comparison:\n",
      "  Baseline: 265 unique kernels\n",
      "  Modified: 265 unique kernels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel Invocation Changes (for common kernels):\n",
      "  ✓ All common kernels have identical invocation counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel Family Analysis (by name pattern):\n",
      "\n",
      "  Pattern: 'set_prognostic_edmf_precomputed_quantities'\n",
      "    Invocations:   1245 →   1245 (+0.0%)\n",
      "    Total time:    46.46 ms →   46.18 ms (-0.6%)\n",
      "\n",
      "  Pattern: 'microphysics'\n",
      "    Invocations:   2480 →   2480 (+0.0%)\n",
      "    Total time:   555.25 ms →  339.93 ms (-38.8%)\n",
      "\n",
      "  Pattern: 'precipitation'\n",
      "    Invocations:   1580 →   1580 (+0.0%)\n",
      "    Total time:    50.58 ms →   50.08 ms (-1.0%)\n",
      "\n",
      "  Pattern: 'tendency'\n",
      "    Invocations:   6695 →   6695 (+0.0%)\n",
      "    Total time:   921.99 ms →  705.00 ms (-23.5%)\n",
      "\n",
      "  Pattern: 'implicit'\n",
      "    Invocations:  11810 →  11810 (+0.0%)\n",
      "    Total time:   810.60 ms →  805.04 ms (-0.7%)\n"
     ]
    }
   ],
   "source": [
    "# --- Total profiling duration analysis ---\n",
    "def get_total_duration(db_path):\n",
    "    \"\"\"Get total duration of the profiling session.\"\"\"\n",
    "    import sqlite3\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    query = \"\"\"\n",
    "    SELECT MIN(start) as first_event, MAX(end) as last_event\n",
    "    FROM CUPTI_ACTIVITY_KIND_KERNEL\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "    if result[0] is not None and result[1] is not None:\n",
    "        return result[1] - result[0]  # nanoseconds\n",
    "    return None\n",
    "\n",
    "\n",
    "baseline_duration = get_total_duration(baseline_db)\n",
    "mod_duration = get_total_duration(mod_db)\n",
    "\n",
    "assert baseline_duration is not None, \"Could not determine baseline duration\"\n",
    "assert mod_duration is not None, \"Could not determine modified duration\"\n",
    "\n",
    "print(\"\\nTotal Profiling Duration:\")\n",
    "print(f\"  Baseline: {format_duration(baseline_duration)}\")\n",
    "print(f\"  Modified: {format_duration(mod_duration)}\")\n",
    "\n",
    "if mod_duration > baseline_duration:\n",
    "    overhead = ((mod_duration - baseline_duration) / baseline_duration) * 100\n",
    "    print(f\"  ⚠️  Modified run is {overhead:.2f}% LONGER overall\")\n",
    "else:\n",
    "    improvement = (\n",
    "        (baseline_duration - mod_duration) / baseline_duration\n",
    "    ) * 100\n",
    "    print(f\"  ✅ Modified run is {improvement:.2f}% SHORTER overall\")\n",
    "\n",
    "\n",
    "# --- Total GPU kernel time analysis ---\n",
    "def get_total_gpu_time(db_path):\n",
    "    \"\"\"Get total GPU time summed across all kernels.\"\"\"\n",
    "    import sqlite3\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    query = \"\"\"\n",
    "    SELECT SUM(end - start) as total_gpu_ns\n",
    "    FROM CUPTI_ACTIVITY_KIND_KERNEL\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "    return result[0] if result[0] is not None else 0\n",
    "\n",
    "\n",
    "baseline_gpu_time = get_total_gpu_time(baseline_db)\n",
    "mod_gpu_time = get_total_gpu_time(mod_db)\n",
    "\n",
    "print(\"\\nTotal GPU Kernel Time:\")\n",
    "print(f\"  Baseline: {format_duration(baseline_gpu_time)}\")\n",
    "print(f\"  Modified: {format_duration(mod_gpu_time)}\")\n",
    "\n",
    "gpu_time_diff = ((mod_gpu_time - baseline_gpu_time) / baseline_gpu_time) * 100\n",
    "sign = \"+\" if gpu_time_diff > 0 else \"\"\n",
    "print(f\"  Change: {sign}{gpu_time_diff:.2f}%\")\n",
    "\n",
    "# Calculate \"idle\" time (wall time - GPU time)\n",
    "baseline_idle = baseline_duration - baseline_gpu_time  # type: ignore\n",
    "mod_idle = mod_duration - mod_gpu_time  # type: ignore\n",
    "\n",
    "print(\"\\nCPU/Sync Overhead (Total Duration - GPU Time):\")\n",
    "print(f\"  Baseline: {format_duration(baseline_idle)}\")\n",
    "print(f\"  Modified: {format_duration(mod_idle)}\")\n",
    "\n",
    "if mod_idle > baseline_idle:\n",
    "    overhead_increase = ((mod_idle - baseline_idle) / baseline_idle) * 100\n",
    "    print(f\"  ⚠️  Modified has {overhead_increase:.2f}% MORE overhead\")\n",
    "else:\n",
    "    overhead_decrease = ((baseline_idle - mod_idle) / baseline_idle) * 100\n",
    "    print(f\"  ✅ Modified has {overhead_decrease:.2f}% LESS overhead\")\n",
    "\n",
    "\n",
    "# --- Kernel count and new/missing kernels ---\n",
    "def get_all_kernel_names(db_path):\n",
    "    \"\"\"Get all unique kernel names in the database.\"\"\"\n",
    "    import sqlite3\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    query = \"\"\"\n",
    "    SELECT DISTINCT s.value\n",
    "    FROM CUPTI_ACTIVITY_KIND_KERNEL k\n",
    "    JOIN StringIds s ON k.demangledName = s.id\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    results = {row[0] for row in cursor.fetchall()}\n",
    "    conn.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "baseline_kernel_set = get_all_kernel_names(baseline_db)\n",
    "mod_kernel_set = get_all_kernel_names(mod_db)\n",
    "\n",
    "# Remove _mod_ from names for comparison\n",
    "mod_kernel_set = {name.replace(\"_mod_\", \"_\") for name in mod_kernel_set}\n",
    "\n",
    "print(\"\\nKernel Count Comparison:\")\n",
    "print(f\"  Baseline: {len(baseline_kernel_set)} unique kernels\")\n",
    "print(f\"  Modified: {len(mod_kernel_set)} unique kernels\")\n",
    "\n",
    "new_kernels = mod_kernel_set - baseline_kernel_set\n",
    "removed_kernels = baseline_kernel_set - mod_kernel_set\n",
    "\n",
    "if new_kernels:\n",
    "    print(f\"\\n⚠️  {len(new_kernels)} NEW kernels in modified:\")\n",
    "    for kernel in sorted(new_kernels)[:10]:\n",
    "        print(f\"    + {kernel}\")\n",
    "    if len(new_kernels) > 10:\n",
    "        print(f\"    ... and {len(new_kernels) - 10} more\")\n",
    "\n",
    "if removed_kernels:\n",
    "    print(f\"\\n✅ {len(removed_kernels)} kernels REMOVED in modified:\")\n",
    "    for kernel in sorted(removed_kernels)[:10]:\n",
    "        print(f\"    - {kernel}\")\n",
    "    if len(removed_kernels) > 10:\n",
    "        print(f\"    ... and {len(removed_kernels) - 10} more\")\n",
    "\n",
    "\n",
    "# --- Kernel invocation count changes ---\n",
    "def get_kernel_invocation_counts(db_path):\n",
    "    \"\"\"Get invocation counts for all kernels.\"\"\"\n",
    "    import sqlite3\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    query = \"\"\"\n",
    "    SELECT s.value, COUNT(*) as count\n",
    "    FROM CUPTI_ACTIVITY_KIND_KERNEL k\n",
    "    JOIN StringIds s ON k.demangledName = s.id\n",
    "    GROUP BY s.value\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    results = {row[0]: row[1] for row in cursor.fetchall()}\n",
    "    conn.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "baseline_counts = get_kernel_invocation_counts(baseline_db)\n",
    "mod_counts = get_kernel_invocation_counts(mod_db)\n",
    "\n",
    "common_kernels = set(baseline_counts.keys()) & set(mod_counts.keys())\n",
    "\n",
    "print(\"\\nKernel Invocation Changes (for common kernels):\")\n",
    "significant_changes = []\n",
    "for kernel in common_kernels:\n",
    "    baseline_count = baseline_counts[kernel]\n",
    "    mod_count = mod_counts[kernel]\n",
    "    if baseline_count != mod_count:\n",
    "        pct_change = ((mod_count - baseline_count) / baseline_count) * 100\n",
    "        significant_changes.append(\n",
    "            (abs(pct_change), kernel, baseline_count, mod_count, pct_change)\n",
    "        )\n",
    "significant_changes.sort(reverse=True)\n",
    "if significant_changes:\n",
    "    print(\"\\nTop 10 kernels with changed invocation counts:\")\n",
    "    for (\n",
    "        _,\n",
    "        kernel,\n",
    "        baseline_count,\n",
    "        mod_count,\n",
    "        pct_change,\n",
    "    ) in significant_changes[:10]:\n",
    "        sign = \"+\" if pct_change > 0 else \"\"\n",
    "        print(\n",
    "            f\"  {sign}{pct_change:+6.1f}%: {baseline_count:>6} → {mod_count:>6} : {kernel[:80]}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"  ✓ All common kernels have identical invocation counts\")\n",
    "\n",
    "\n",
    "# --- Kernel family analysis ---\n",
    "def aggregate_by_pattern(counts_dict, duration_dict, pattern):\n",
    "    \"\"\"Aggregate kernels matching a pattern.\"\"\"\n",
    "    total_count = 0\n",
    "    total_duration = 0\n",
    "    for kernel_name in counts_dict:\n",
    "        if pattern in kernel_name:\n",
    "            total_count += counts_dict[kernel_name]\n",
    "            total_duration += duration_dict.get(kernel_name, 0)\n",
    "    return total_count, total_duration\n",
    "\n",
    "\n",
    "def get_kernel_durations(db_path):\n",
    "    \"\"\"Get total duration for each kernel.\"\"\"\n",
    "    import sqlite3\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    query = \"\"\"\n",
    "    SELECT s.value, SUM(k.end - k.start) as total_ns\n",
    "    FROM CUPTI_ACTIVITY_KIND_KERNEL k\n",
    "    JOIN StringIds s ON k.demangledName = s.id\n",
    "    GROUP BY s.value\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    results = {row[0]: row[1] for row in cursor.fetchall()}\n",
    "    conn.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "baseline_durations = get_kernel_durations(baseline_db)\n",
    "mod_durations = get_kernel_durations(mod_db)\n",
    "\n",
    "patterns_to_check = [\n",
    "    \"set_prognostic_edmf_precomputed_quantities\",\n",
    "    \"microphysics\",\n",
    "    \"precipitation\",\n",
    "    \"tendency\",\n",
    "    \"implicit\",\n",
    "    \"ldiv\",\n",
    "    \"Wfact\",\n",
    "]\n",
    "\n",
    "print(\"\\nKernel Family Analysis (by name pattern):\")\n",
    "for pattern in patterns_to_check:\n",
    "    baseline_count, baseline_duration = aggregate_by_pattern(\n",
    "        baseline_counts, baseline_durations, pattern\n",
    "    )\n",
    "    mod_count, mod_duration = aggregate_by_pattern(\n",
    "        mod_counts, mod_durations, pattern\n",
    "    )\n",
    "    if baseline_count > 0 or mod_count > 0:\n",
    "        count_change = (\n",
    "            ((mod_count - baseline_count) / max(baseline_count, 1)) * 100\n",
    "            if baseline_count > 0\n",
    "            else float(\"inf\")\n",
    "        )\n",
    "        duration_change = (\n",
    "            ((mod_duration - baseline_duration) / max(baseline_duration, 1))\n",
    "            * 100\n",
    "            if baseline_duration > 0\n",
    "            else float(\"inf\")\n",
    "        )\n",
    "        print(f\"\\n  Pattern: '{pattern}'\")\n",
    "        print(\n",
    "            f\"    Invocations: {baseline_count:>6} → {mod_count:>6} ({count_change:+.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"    Total time:  {format_duration(baseline_duration):>10} → {format_duration(mod_duration):>10} ({duration_change:+.1f}%)\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clima-local-geometry: py",
   "language": "python",
   "name": "clima-local-geometry-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.114348,
   "end_time": "2026-02-27T17:44:04.893276",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/compare-kernels.ipynb",
   "output_path": ".calkit/notebooks/executed/notebooks/compare-kernels.ipynb",
   "parameters": {},
   "start_time": "2026-02-27T17:44:02.778928",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}